{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hotel Guest Sentiment Analysis - NLP Project\n",
        "\n",
        "This notebook provides a comprehensive analysis of hotel guest reviews using Natural Language Processing (NLP) techniques.\n",
        "\n",
        "## Project Overview\n",
        "- **Data Collection and Preparation**: Clean and preprocess hotel reviews\n",
        "- **Sentiment Analysis**: Classify reviews as positive, negative, or neutral\n",
        "- **Visualization**: Create charts and graphs to understand sentiment distribution\n",
        "- **Aspect Analysis**: Identify key aspects mentioned in reviews\n",
        "\n",
        "## Dataset\n",
        "Real-world hotel reviews dataset with 56 reviews including sentiment labels and primary aspects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLP Libraries\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Data Collection and Preparation\n",
        "\n",
        "Load the dataset and perform text cleaning and preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('data/hotel_reviews_dataset.csv')\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"\\nDataset columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data cleaning and preparation function\n",
        "def prepare_text(text):\n",
        "    \"\"\"\n",
        "    Clean and prepare text for sentiment analysis\n",
        "    - Convert to lowercase (already done in dataset)\n",
        "    - Remove special characters\n",
        "    - Remove extra whitespace\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    # Remove special characters but keep basic punctuation\n",
        "    text = re.sub(r'[^\\w\\s\\.\\!\\?]', '', text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_text'] = df['Cleaned Text (Lowercased)'].apply(prepare_text)\n",
        "\n",
        "print(\"Text cleaning completed!\")\n",
        "print(f\"\\nSample cleaned text:\")\n",
        "print(df[['Review ID', 'Cleaned Text (Lowercased)', 'cleaned_text']].head(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data quality\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Total reviews: {len(df)}\")\n",
        "print(f\"Missing values in cleaned text: {df['cleaned_text'].isna().sum()}\")\n",
        "print(f\"\\nSentiment distribution:\")\n",
        "print(df['Sentiment'].value_counts())\n",
        "print(f\"\\nPercentage distribution:\")\n",
        "print(df['Sentiment'].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Sentiment Analysis\n",
        "\n",
        "Perform sentiment analysis using TextBlob to classify reviews as positive, negative, or neutral.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyze sentiment of a review using TextBlob\n",
        "    Returns: sentiment label and polarity score\n",
        "    \"\"\"\n",
        "    # Create TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "    \n",
        "    # Get polarity (-1 to 1)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    \n",
        "    # Classify sentiment\n",
        "    if polarity > 0:\n",
        "        sentiment = 'positive'\n",
        "    elif polarity < 0:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'neutral'\n",
        "    \n",
        "    return {\n",
        "        'sentiment': sentiment,\n",
        "        'polarity': round(polarity, 3),\n",
        "        'subjectivity': round(blob.sentiment.subjectivity, 3)\n",
        "    }\n",
        "\n",
        "# Apply sentiment analysis to all reviews\n",
        "print(\"Performing sentiment analysis...\")\n",
        "results = []\n",
        "for idx, row in df.iterrows():\n",
        "    result = analyze_sentiment(row['cleaned_text'])\n",
        "    result['review_id'] = row['Review ID']\n",
        "    result['review'] = row['cleaned_text']\n",
        "    results.append(result)\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "df = df.merge(results_df[['review_id', 'sentiment', 'polarity', 'subjectivity']], \n",
        "              left_on='Review ID', right_on='review_id', how='left')\n",
        "\n",
        "print(\"Sentiment analysis completed!\")\n",
        "print(f\"\\nPredicted sentiment distribution:\")\n",
        "print(df['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare actual vs predicted sentiment\n",
        "print(\"=\" * 60)\n",
        "print(\"SENTIMENT ANALYSIS RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Map actual sentiment to lowercase for comparison\n",
        "df['actual_sentiment_lower'] = df['Sentiment'].str.lower()\n",
        "\n",
        "# Calculate accuracy (treating 'mixed' as 'neutral')\n",
        "df['actual_mapped'] = df['actual_sentiment_lower'].replace('mixed', 'neutral')\n",
        "accuracy = (df['sentiment'] == df['actual_mapped']).sum() / len(df) * 100\n",
        "\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Correct predictions: {(df['sentiment'] == df['actual_mapped']).sum()}/{len(df)}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "confusion = pd.crosstab(df['actual_mapped'], df['sentiment'], margins=True)\n",
        "print(confusion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample results\n",
        "print(\"\\nSample Analysis Results:\")\n",
        "print(\"=\" * 60)\n",
        "sample_df = df[['Review ID', 'Sentiment', 'sentiment', 'polarity', 'subjectivity', 'cleaned_text', 'actual_mapped']].head(10)\n",
        "for idx, row in sample_df.iterrows():\n",
        "    match = \"MATCH\" if row['sentiment'] == row['actual_mapped'] else \"NO MATCH\"\n",
        "    print(f\"\\nReview {row['Review ID']}:\")\n",
        "    print(f\"  Text: {row['cleaned_text'][:80]}...\")\n",
        "    print(f\"  Actual: {row['Sentiment']} | Predicted: {row['sentiment']} | Match: {match}\")\n",
        "    print(f\"  Polarity: {row['polarity']:.3f} | Subjectivity: {row['subjectivity']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Visualizing Sentiment Distribution\n",
        "\n",
        "Create visualizations to understand sentiment distribution across reviews.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Hotel Review Sentiment Analysis - Comprehensive Dashboard', \n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "# 1. Actual Sentiment Distribution (Bar Chart)\n",
        "ax1 = axes[0, 0]\n",
        "actual_counts = df['Sentiment'].value_counts()\n",
        "colors = {'Positive': '#2ecc71', 'Negative': '#e74c3c', 'Mixed': '#f39c12'}\n",
        "bars1 = ax1.bar(actual_counts.index, actual_counts.values, \n",
        "                color=[colors.get(s, '#95a5a6') for s in actual_counts.index])\n",
        "ax1.set_title('Actual Sentiment Distribution', fontweight='bold')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. Predicted Sentiment Distribution (Bar Chart)\n",
        "ax2 = axes[0, 1]\n",
        "predicted_counts = df['sentiment'].value_counts()\n",
        "colors_pred = {'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#f39c12'}\n",
        "bars2 = ax2.bar(predicted_counts.index, predicted_counts.values,\n",
        "                color=[colors_pred.get(s, '#95a5a6') for s in predicted_counts.index])\n",
        "ax2.set_title('Predicted Sentiment Distribution', fontweight='bold')\n",
        "ax2.set_ylabel('Count')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3. Actual Sentiment Distribution (Pie Chart)\n",
        "ax3 = axes[0, 2]\n",
        "ax3.pie(actual_counts.values, labels=actual_counts.index, autopct='%1.1f%%',\n",
        "        colors=[colors.get(s, '#95a5a6') for s in actual_counts.index],\n",
        "        startangle=90, textprops={'fontweight': 'bold'})\n",
        "ax3.set_title('Actual Sentiment (Percentage)', fontweight='bold')\n",
        "\n",
        "# 4. Polarity Distribution Histogram\n",
        "ax4 = axes[1, 0]\n",
        "ax4.hist(df['polarity'], bins=20, color='#3498db', edgecolor='black', alpha=0.7)\n",
        "ax4.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Neutral')\n",
        "ax4.set_title('Polarity Score Distribution', fontweight='bold')\n",
        "ax4.set_xlabel('Polarity Score')\n",
        "ax4.set_ylabel('Frequency')\n",
        "ax4.legend()\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 5. Polarity by Actual Sentiment (Box Plot)\n",
        "ax5 = axes[1, 1]\n",
        "sentiment_order = ['Positive', 'Mixed', 'Negative']\n",
        "polarity_data = [df[df['Sentiment'] == s]['polarity'].values \n",
        "                 for s in sentiment_order if s in df['Sentiment'].values]\n",
        "labels = [s for s in sentiment_order if s in df['Sentiment'].values]\n",
        "bp = ax5.boxplot(polarity_data, tick_labels=labels, patch_artist=True)\n",
        "for patch, label in zip(bp['boxes'], labels):\n",
        "    patch.set_facecolor(colors.get(label, '#95a5a6'))\n",
        "ax5.set_title('Polarity by Actual Sentiment', fontweight='bold')\n",
        "ax5.set_ylabel('Polarity Score')\n",
        "ax5.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 6. Polarity vs Subjectivity Scatter\n",
        "ax6 = axes[1, 2]\n",
        "for sentiment in df['Sentiment'].unique():\n",
        "    subset = df[df['Sentiment'] == sentiment]\n",
        "    ax6.scatter(subset['subjectivity'], subset['polarity'], \n",
        "               label=sentiment, color=colors.get(sentiment, '#95a5a6'),\n",
        "               alpha=0.6, s=60)\n",
        "ax6.set_title('Polarity vs Subjectivity', fontweight='bold')\n",
        "ax6.set_xlabel('Subjectivity')\n",
        "ax6.set_ylabel('Polarity')\n",
        "ax6.legend()\n",
        "ax6.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('sentiment_analysis_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Visualizations saved as 'sentiment_analysis_dashboard.png'\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aspect Analysis\n",
        "\n",
        "Analyze the primary aspects mentioned in reviews and their sentiment distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and analyze aspects\n",
        "from collections import Counter\n",
        "\n",
        "def extract_aspects(aspect_string):\n",
        "    \"\"\"Extract individual aspects from the Primary Aspect column\"\"\"\n",
        "    if pd.isna(aspect_string):\n",
        "        return []\n",
        "    aspects = [a.strip() for a in str(aspect_string).split('&')]\n",
        "    return aspects\n",
        "\n",
        "# Extract all aspects\n",
        "all_aspects = []\n",
        "for aspect_str in df['Primary Aspect'].dropna():\n",
        "    aspects = extract_aspects(aspect_str)\n",
        "    all_aspects.extend(aspects)\n",
        "\n",
        "aspect_counts = Counter(all_aspects)\n",
        "\n",
        "print(\"Top 10 Most Mentioned Aspects:\")\n",
        "print(\"=\" * 60)\n",
        "for aspect, count in aspect_counts.most_common(10):\n",
        "    print(f\"{aspect:30s}: {count:3d} times\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top aspects\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Top 10 Aspects Bar Chart\n",
        "ax1 = axes[0]\n",
        "top_10_aspects = dict(aspect_counts.most_common(10))\n",
        "ax1.barh(range(len(top_10_aspects)), list(top_10_aspects.values()), color='#9b59b6')\n",
        "ax1.set_yticks(range(len(top_10_aspects)))\n",
        "ax1.set_yticklabels(list(top_10_aspects.keys()))\n",
        "ax1.set_title('Top 10 Most Mentioned Aspects', fontweight='bold', fontsize=12)\n",
        "ax1.set_xlabel('Frequency')\n",
        "ax1.invert_yaxis()\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "for i, (aspect, count) in enumerate(top_10_aspects.items()):\n",
        "    ax1.text(count + 0.5, i, str(count), va='center', fontweight='bold')\n",
        "\n",
        "# Sentiment Distribution by Top 5 Aspects\n",
        "ax2 = axes[1]\n",
        "top_5_aspects = [a[0] for a in aspect_counts.most_common(5)]\n",
        "aspect_sentiment_data = []\n",
        "aspect_labels = []\n",
        "\n",
        "for aspect in top_5_aspects:\n",
        "    aspect_reviews = df[df['Primary Aspect'].str.contains(aspect, case=False, na=False)]\n",
        "    if len(aspect_reviews) > 0:\n",
        "        sentiment_dist = aspect_reviews['Sentiment'].value_counts()\n",
        "        aspect_labels.append(f\"{aspect}\\n(n={len(aspect_reviews)})\")\n",
        "        aspect_sentiment_data.append([\n",
        "            sentiment_dist.get('Positive', 0),\n",
        "            sentiment_dist.get('Negative', 0),\n",
        "            sentiment_dist.get('Mixed', 0)\n",
        "        ])\n",
        "\n",
        "if aspect_sentiment_data:\n",
        "    aspect_sentiment_df = pd.DataFrame(aspect_sentiment_data, \n",
        "                                       index=aspect_labels,\n",
        "                                       columns=['Positive', 'Negative', 'Mixed'])\n",
        "    aspect_sentiment_df.plot(kind='bar', stacked=True, ax=ax2, \n",
        "                            color=['#2ecc71', '#e74c3c', '#f39c12'])\n",
        "    ax2.set_title('Sentiment Distribution by Top 5 Aspects', fontweight='bold', fontsize=12)\n",
        "    ax2.set_ylabel('Count')\n",
        "    ax2.legend(title='Sentiment')\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('aspect_analysis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Aspect analysis visualization saved as 'aspect_analysis.png'\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics\n",
        "\n",
        "Generate comprehensive statistics and save results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary statistics\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nDataset Overview:\")\n",
        "print(f\"  Total Reviews: {len(df)}\")\n",
        "print(f\"  Average Review Length: {df['cleaned_text'].str.len().mean():.1f} characters\")\n",
        "\n",
        "print(f\"\\nSentiment Distribution (Actual):\")\n",
        "for sentiment, count in df['Sentiment'].value_counts().items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"  {sentiment:10s}: {count:3d} reviews ({percentage:5.2f}%)\")\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"  Correct Predictions: {(df['sentiment'] == df['actual_mapped']).sum()}/{len(df)}\")\n",
        "\n",
        "print(f\"\\nPolarity Statistics:\")\n",
        "print(f\"  Average Polarity: {df['polarity'].mean():.3f}\")\n",
        "print(f\"  Median Polarity: {df['polarity'].median():.3f}\")\n",
        "print(f\"  Min Polarity: {df['polarity'].min():.3f}\")\n",
        "print(f\"  Max Polarity: {df['polarity'].max():.3f}\")\n",
        "print(f\"  Standard Deviation: {df['polarity'].std():.3f}\")\n",
        "\n",
        "print(f\"\\nPolarity by Sentiment:\")\n",
        "for sentiment in df['Sentiment'].unique():\n",
        "    subset = df[df['Sentiment'] == sentiment]\n",
        "    print(f\"  {sentiment:10s}: {subset['polarity'].mean():.3f} (avg)\")\n",
        "\n",
        "print(f\"\\nAspect Analysis:\")\n",
        "print(f\"  Total Unique Aspects: {len(aspect_counts)}\")\n",
        "print(f\"  Most Common Aspect: {aspect_counts.most_common(1)[0][0]} ({aspect_counts.most_common(1)[0][1]} mentions)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to CSV\n",
        "output_df = df[['Review ID', 'Sentiment', 'Primary Aspect', 'cleaned_text', \n",
        "                'sentiment', 'polarity', 'subjectivity']].copy()\n",
        "output_df.columns = ['Review_ID', 'Actual_Sentiment', 'Primary_Aspect', 'Review_Text',\n",
        "                    'Predicted_Sentiment', 'Polarity', 'Subjectivity']\n",
        "output_df.to_csv('sentiment_analysis_results.csv', index=False)\n",
        "\n",
        "print(\"[SUCCESS] Results saved to 'sentiment_analysis_results.csv'\")\n",
        "print(\"\\nGenerated Files:\")\n",
        "print(\"  - sentiment_analysis_dashboard.png\")\n",
        "print(\"  - aspect_analysis.png\")\n",
        "print(\"  - sentiment_analysis_results.csv\")\n",
        "print(\"\\nAnalysis Complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
